{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989f6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def data_preprocessing_pipeline(data):\n",
    "    #Identify numeric and categorical features\n",
    "    numeric_features = data.select_dtypes(include=['float', 'int']).columns\n",
    "    categorical_features = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "    #Handle missing values in numeric features\n",
    "    data[numeric_features] = data[numeric_features].fillna(data[numeric_features].mean())\n",
    "\n",
    "    #Detect and handle outliers in numeric features using IQR\n",
    "    for feature in numeric_features:\n",
    "        Q1 = data[feature].quantile(0.25)\n",
    "        Q3 = data[feature].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "        data[feature] = np.where((data[feature] < lower_bound) | (data[feature] > upper_bound),\n",
    "                                 data[feature].mean(), data[feature])\n",
    "\n",
    "    #Normalize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[numeric_features])\n",
    "    data[numeric_features] = scaler.transform(data[numeric_features])\n",
    "\n",
    "    #Handle missing values in categorical features\n",
    "    data[categorical_features]= data[categorical_features].fillna(data[categorical_features].mode().iloc[0])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e239944b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: \n",
      "   NumericFeature1  NumericFeature2 CategoricalFeature\n",
      "0              1.0                7                  A\n",
      "1              2.0                8                  B\n",
      "2              NaN                9                NaN\n",
      "3              4.0               10                  A\n",
      "4              5.0               11                  B\n",
      "5              6.0               50                  C\n"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv(\"data.csv\")\n",
    "\n",
    "print(\"Original dataset: \")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8bf76eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset: \n",
      "   NumericFeature1  NumericFeature2 CategoricalFeature\n",
      "0        -1.535624        -1.099370                  A\n",
      "1        -0.944999        -0.749128                  B\n",
      "2         0.000000        -0.398886                  A\n",
      "3         0.236250        -0.048645                  A\n",
      "4         0.826874         0.301597                  B\n",
      "5         1.417499         1.994431                  C\n"
     ]
    }
   ],
   "source": [
    "cleaned_data= data_preprocessing_pipeline(data)\n",
    "\n",
    "print(\"Preprocessed dataset: \")\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4478f",
   "metadata": {},
   "source": [
    "# Data Preprocessing Explanation\n",
    "\n",
    "From the comparison between the original and preprocessed datasets, it is evident that several preprocessing steps were applied to the data. Here's an explanation of the transformations observed:\n",
    "\n",
    "## 1. Handling Missing Values\n",
    "\n",
    "- **NumericFeature1**: The `NaN` value in the third row was filled. This appears to have been done using the mean value of the other entries in this column, which is a common approach for imputing missing numeric values.\n",
    "- **CategoricalFeature**: The missing value in the third row was replaced with 'A', which is the most frequent category or mode in this column.\n",
    "\n",
    "## 2. Normalization/Standardization of Numeric Features\n",
    "\n",
    "Both numeric columns (`NumericFeature1` and `NumericFeature2`) have been standardized. The transformation involves the following steps:\n",
    "- Subtract the mean of the column from each entry.\n",
    "- Divide the result by the standard deviation of the column.\n",
    "\n",
    "This adjusts the data so that the mean of each numeric feature is 0 and the standard deviation is 1, reducing feature scale bias in modeling processes.\n",
    "\n",
    "## 3. No Change in Categorical Features Except for Missing Value Imputation\n",
    "\n",
    "- The categorical values remain unchanged except for the imputation of the missing value. There is no indication of encoding in the data snippet provided (e.g., converting categorical data to numerical values), which is often done in many machine learning workflows to facilitate modeling.\n",
    "\n",
    "## Summary\n",
    "\n",
    "These preprocessing steps are critical for preparing the dataset for effective analysis, particularly in statistical or machine learning models. They ensure that the features are normalized and that the dataset is free from basic issues like missing data, making it suitable for further analysis and modeling.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee910d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
